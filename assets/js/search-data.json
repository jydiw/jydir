{
  
    
        "post0": {
            "title": "COVID-19 County Analysis",
            "content": "The most recent polling from Civiqs shows a large discrepancy in COVID-19 sentiment, split along party lines: . Party ExtremelyConcerned ModeratelyConcerned A LittleConcerned Not ConcernedAt All Unsure . Democrat | 63% | 27% | 8% | 2% | &lt;1% | . Republican | 10% | 22% | 29% | 38% | &lt;1% | . Independent | 34% | 26% | 19% | 20% | &lt;1% | . Because of this, it can be easy for one&#39;s own party to blame the other, when the reality is probably more complex. . This post will focus on the following factors and how they relate to up-to-date COVID-19 data. . About . Data Sources . The New York Times COVID-19 repository | The United States Census | Plotly&#39;s county-level GeoJSON | nomanatim and polygons | github.com/tonmcg and RRH Elections | . How this data was merged . Refer to my COVID-19 repository for information on how this data was merged. . Exploring the Correlations . The following are, upon shallow inspection, positively correlated with the total number of cases and deaths per county: . population density (pop_density) | percent black (per_black) | percent hispanic (per_hispanic) | percent of 25y+ without high school diploma or GED (per_no_hs) | . The following are negatively correlated with the total number of cases and deaths per county: . percent white (per_white) | adjusted percent votes GOP in the 2016 general election (per_gop) | educational coefficient (edu) | mask discipline (mask) | . Text(0.5, 0.98, &#39;covid correlation heatmap&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Scatter Plots (with color and size axes) . In each chart: . color -- percent GOP (calculated as 2-party percentage) in the 2016 general election | size -- total cases | . #collapse-hide def make_bubble_chart(df, x_col, y_col, c_col, s_col=&#39;cases&#39;, x_scale=&#39;linear&#39;, y_scale=&#39;linear&#39;, c_range=None, c_mid=None, line=True, split=False, clip=False): base_cols = [&#39;cases&#39;, &#39;deaths&#39;, &#39;rate&#39;] if s_col not in base_cols: s_col = &#39;cases&#39; cols = [&#39;date&#39;, &#39;state&#39;, &#39;county&#39;, &#39;total_pop&#39;] + base_cols + [x_col, y_col, c_col] cols = list(set(cols)) smax = np.max(df[s_col]) smax = smax + (-smax) % 10 if c_range==None: c_range = color_dict[c_col][&#39;range&#39;] if c_mid==None: c_mid = color_dict[c_col][&#39;mid&#39;] df = df[cols] base = alt.Chart(df).properties( title=f&#39;{y_col} vs. {x_col} ({c_col}, cases)&#39;, width=720, height=480 ) circles = base.mark_circle(stroke=&#39;black&#39;, strokeWidth=0.25, opacity=0.8).encode( x=alt.X( f&#39;{x_col}:Q&#39;, scale=alt.Scale(type=x_scale, zero=False) ), y=alt.Y( f&#39;{y_col}:Q&#39;, scale=alt.Scale(type=y_scale, zero=False) ), size=alt.Size( f&#39;{s_col}:Q&#39;, scale=alt.Scale( domain=[1,smax], range=[10,2000] ), ), color=alt.Color( f&#39;{c_col}:Q&#39;, scale=alt.Scale( range=c_range, domain=[np.percentile(pop_df_ac[c_col], 1), c_mid, np.percentile(pop_df_ac[c_col], 99)], interpolate={ &#39;type&#39;:&#39;rgb&#39;, &#39;gamma&#39;:0.75 } ), ), tooltip=[ &#39;state:N&#39;, &#39;county:N&#39;, &#39;cases:Q&#39;, &#39;deaths:Q&#39;, alt.Tooltip( &#39;rate:Q&#39;, format=&#39;.3f&#39; ), alt.Tooltip( f&#39;{c_col}:Q&#39;, format=&#39;.2f&#39;, ), alt.Tooltip( f&#39;{y_col}:Q&#39;, format=&#39;.2f&#39;, ), alt.Tooltip( f&#39;{x_col}:Q&#39;, format=&#39;.2f&#39;, ) ] ) def make_line(split=False, side=None): if split: if side==&#39;gt&#39;: df_ = df[df[c_col]&gt;c_mid] color = c_range[-1] elif side==&#39;lt&#39;: df_ = df[df[c_col]&lt;=c_mid] color = c_range[0] else: df_ = df color = &#39;black&#39; pfit = poly.polyfit( df_[x_col], df_[y_col], 1, w=df_[&#39;total_pop&#39;] ) fit = poly.polyval(np.unique(df_[x_col]), pfit) line_df = pd.DataFrame({ &#39;x&#39;: np.unique(df_[x_col]), &#39;y&#39;: fit }) return alt.Chart(line_df).mark_line( color=color, strokeDash=[2,1], clip=True ).encode( x=&#39;x:Q&#39;, y=alt.Y( &#39;y:Q&#39;, scale=alt.Scale(domain=[ df_[y_col].min(), df_[y_col].max() ]) ) ) if line: if split: _line0 = make_line(True, &#39;lt&#39;) _line1 = make_line(True, &#39;gt&#39;) return circles + _line0 + _line1 else: _line = make_line() return circles + _line else: return circles . . COVID-19 Density and Mortality Rate vs. Population Density . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . By far the largest predictor of total cases/deaths is population density. This does not appear to be an unfair characterization, given the fact that the disease spreads from person-to-person. Dense urban centers tend to lean Democratic, whereas sparse rural counties tend to lean Republican. Therefore, it makes sense that urban Democratic centers are being hit harder than their rural Republican counterparts. . The effects of urban density are further illustrated when discussing the mortality rate. In New York City, over 10% of those diagnosed have passed due to complications from the virus. . df_slice[&#39;rate&#39;].describe() . count 575.000000 mean 0.027115 std 0.024421 min 0.000000 25% 0.010816 50% 0.019680 75% 0.035000 max 0.166667 Name: rate, dtype: float64 . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . COVID-19 Density vs. Median Income . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . COVID-19 Density vs. Educational Attainment . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . Educational attainment (edu) is defined as the weighted average of the highest degree of education for persons 25 and older within a given county: . no HS -- 0 | some HS -- 1 | HS diploma or GED -- 2 | some college -- 3 | associate&#39;s degree -- 4 | bachelor&#39;s degree -- 5 | graduate or professional degree - 6 | . COVID-19 Density vs. Mask Discipline . Mask discipline (edu) is defined as the weighted average of the answer to the following question: &quot;How often do you wear a mask in public when you expect to be within six feet of another person?&quot; . never -- 0 | rarely -- 1 | sometimes -- 2 | frequently -- 3 | always -- 4 | . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . make_bubble_chart(df_slice, &#39;per_gop&#39;, &#39;cases_per_100k&#39;, &#39;mask&#39;, x_scale=&#39;linear&#39;, y_scale=&#39;sqrt&#39;, split=True) . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . New Cases per 100k vs. Population Density, Education, and Mask Discipline . Mask use seems to increase with educational attainment and is somehow a partisan issue, with Republican counties having worse mask discipline. With the size of the circles representing new cases, we see that counties with a high education attainment and mask discipline ratines (top-right quadrant) seem to have a lower number of new cases than those with low education and mask discipline (bottom-left quadrant). . New Cases per 100k vs. Percent GOP . Recent COVID-19 cases, however, seem to be more prevalent in more GOP-weighted counties. . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . This is most likely skewed by the fact that New York City -- a prior epicenter of COVID-19 cases and the largest group in this dataset -- has relatively few cases now. . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . Change in New Cases per 100k vs. Percent GOP . Changes in cases do not seem to be predicted by political affiliation. . make_bubble_chart(df_slice, &#39;per_gop&#39;, &#39;delta_new_cases_per_100k_15sg&#39;, &#39;per_gop&#39;, x_scale=&#39;linear&#39;, y_scale=&#39;sqrt&#39;, line=True, split=True) . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html . Case Rate Charts . Counties in the upper right portion of this chart face the highest risk of a worsening pandemic. . &lt;VegaLite 4 object&gt; If you see this message, it means the renderer has not been properly enabled for the frontend that you are using. For more information, see https://altair-viz.github.io/user_guide/troubleshooting.html .",
            "url": "https://jydiw.github.io/jydir/covid-19/data-visualization/2020/09/07/_old_2020-07-30-covid-misconceptions.html",
            "relUrl": "/covid-19/data-visualization/2020/09/07/_old_2020-07-30-covid-misconceptions.html",
            "date": " • Sep 7, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19: A Socio-political Virus, but Not Quite How You'd Think",
            "content": "DISCLAIMER: I lean left in my political ideologies. I respect the CDC and believe masks, while not completely effective, are the easiest way to prevent the spread of respiratory diseases when we are unable to socially distance. . The most recent polling from Civiqs (updated Sept. 2) shows a large discrepancy in COVID-19 sentiment, split along party lines: . Party ExtremelyConcerned ModeratelyConcerned A LittleConcerned Not ConcernedAt All Unsure . Democrat | 52% | 35% | 10% | 3% | &lt;1% | . Republican | 7% | 19% | 28% | 46% | &lt;1% | . Independent | 24% | 30% | 22% | 24% | &lt;1% | . Because of this, it can be easy for one&#39;s own party to blame the other, when the reality is probably more complex. . COVID-19 sentiment also appears to be split across race, as well: . Race ExtremelyConcerned ModeratelyConcerned A LittleConcerned Not ConcernedAt All Unsure . White | 22% | 28% | 22% | 28% | &lt;1% | . Black | 58% | 27% | 10% | 4% | &lt;1% | . Hispanic | 43% | 29% | 15% | 14% | &lt;1% | . Other | 34% | 31% | 16% | 19% | &lt;1% | . This post will explore various demographic factors and how they relate to up-to-date COVID-19 data. . About . Data Sources . The New York Times COVID-19 repository | The United States Census | nomanatim and polygons | github.com/tonmcg and RRH Elections | . How this data was merged . Refer to my COVID-19 repository for notebooks describing how this data was processed. . #collapse-hide def column_selector(info_df, columns=&#39;none&#39;, mask=[], exclude=[]): # only select from numeric columns all_columns = info_df.select_dtypes(include=&#39;number&#39;).columns.tolist() # empty container if we don&#39;t have a list going already if columns is &#39;none&#39;: columns = [] elif columns is &#39;all&#39;: return all_columns # includes all columns that have all elements in mask # excludes all columns that have any elements in exclude new_columns = all_columns if len(mask + exclude) &gt; 0: if len(mask) &gt; 0: new_columns = list(set([c for c in new_columns if all(m in set(re.findall(&#39;[a-z]+&#39;, c)) for m in mask)])) if len(exclude) &gt; 0: new_columns = list(set([c for c in new_columns if all(e not in set(re.findall(&#39;[a-z]+&#39;, c)) for e in exclude)])) columns += new_columns return sorted(list(set(columns))) def corr(x, y, w, useweight=True): # only uses elements that are not nan from both lists x_ids = ~np.isnan(x) y_ids = ~np.isnan(y) ids = x_ids &amp; y_ids if useweight: try: [xx, xy], [_, yy] = np.cov(x[ids], y[ids], aweights=w[ids]) except: print(x.name) print(y.name) else: [xx, xy], [_, yy] = np.cov(x[ids], y[ids]) return xy / np.sqrt(xx * yy) def df_merger(nyt_df, info_df, x_cols=None, y_cols=None, date=&#39;latest&#39;, weight=&#39;tot_pop&#39;): # make sure x and y are valid all_y = nyt_df.columns.tolist() for y in y_cols: if &#39;_per_100k&#39; in y: y_cols.append(y.replace(&#39;_per_100k&#39;, &#39;&#39;)) y_cols = sorted(list(set([y for y in y_cols if y in all_y]))) all_x = info_df.columns.tolist() x_cols = sorted(list(set([c for c in x_cols if c in all_x]))) ## only process specific date and y_cols left_columns = list(set([&#39;date&#39;, &#39;fips&#39;] + y_cols)) if date==&#39;latest&#39;: left_df = nyt_df[nyt_df[&#39;date&#39;]==nyt_df[&#39;date&#39;].max()][left_columns] elif date==&#39;all&#39;: left_df = nyt_df[left_columns] else: left_df = nyt_df[nyt_df[&#39;date&#39;]==date][left_columns] ## only process specific x_cols right_columns = list(set([&#39;fips&#39;, &#39;state&#39;, &#39;county&#39;, weight] + x_cols)) right_df = info_df[right_columns] # https://stackoverflow.com/a/47118728/14083095 # fills nyt_df with entries for counties that do not log cases # for more accurate aggregate per capita calculations mux = pd.MultiIndex.from_product([left_df[&#39;date&#39;].unique(), right_df[&#39;fips&#39;].unique()], names=(&#39;date&#39;, &#39;fips&#39;)) left_df = left_df.set_index([&#39;date&#39;,&#39;fips&#39;]).reindex(mux).swaplevel(0,1).reset_index().fillna(0) df = left_df.merge(right_df, on=&#39;fips&#39;, how=&#39;outer&#39;, suffixes=(&#39;_x&#39;, &#39;&#39;)) df = df.drop([x for x in df.columns if x[-2:]==&#39;_x&#39;], axis=1) return df def make_correlation_table( nyt_df, info_df, x_cols=None, y_cols=None, date=&#39;latest&#39;, useweight=True, weight=&#39;tot_pop&#39;, threshold=0.4 ): df = df_merger(nyt_df, info_df, x_cols, y_cols, date, weight) wct = pd.DataFrame(index=x_cols, columns=y_cols) for y in y_cols: for x in x_cols: wct.loc[x, y] = corr(df[y], df[x], df[weight]) wct = wct[(wct &gt;= threshold) | (wct &lt;= -1 * threshold)].dropna() return wct.sort_values(by=y_cols[0], ascending=False) def make_correlation_heatmap( nyt_df, info_df, date=&#39;latest&#39;, x_cols=None, y_cols=[ &#39;cases_per_100k&#39;, &#39;new_cases_per_100k_15d&#39;, &#39;delta_new_cases_per_100k_15d&#39;, &#39;deaths_per_100k&#39;, &#39;new_deaths_per_100k_15d&#39;, &#39;delta_new_deaths_per_100k_15d&#39;, &#39;mortality_rate&#39;, &#39;mortality_rate_15d&#39; ], useweight=True, weight=&#39;tot_pop&#39;, size=50, print_corr=True, threshold=0.4 ): df = df_merger(nyt_df, info_df, x_cols, y_cols, date, weight) # build weighted correlation matrix from df wcm_cols = x_cols + y_cols wcm = pd.DataFrame(index=x_cols, columns=wcm_cols) for y in wcm_cols: for x in x_cols: wcm.loc[x, y] = corr(df[x], df[y], df[weight]) wcm = (wcm.reset_index().rename(columns={&#39;index&#39;:&#39;y_feature&#39;}).dropna() .melt(&#39;y_feature&#39;, var_name=&#39;x_feature&#39;, value_name=&#39;corr&#39;)) wcm[&#39;corr&#39;] = np.round(wcm[&#39;corr&#39;].astype(float), 4) if print_corr: print(&#39;positive correlations&#39;) print( wcm[(wcm[&#39;corr&#39;] &gt;= threshold) &amp; (wcm[&#39;corr&#39;] != 1)] .sort_values(by=[&#39;corr&#39;, &#39;y_feature&#39;]).iloc[::2, :] .sort_values(by=[&#39;y_feature&#39;, &#39;x_feature&#39;]) ) print(&#39; nnegative correlations&#39;) print( wcm[(wcm[&#39;corr&#39;] &lt;= -1 * threshold) &amp; (wcm[&#39;corr&#39;] != -1)] .sort_values(by=[&#39;corr&#39;, &#39;y_feature&#39;]).iloc[::2, :] .sort_values(by=[&#39;y_feature&#39;, &#39;x_feature&#39;]) ) # build altair chart base = alt.Chart(wcm).encode( alt.X( &#39;x_feature:O&#39;, sort=x_cols ), alt.Y( &#39;y_feature:O&#39;, # sort=columns ) ) heatmap = base.mark_rect().encode( color=alt.Color( &#39;corr:Q&#39;, scale=alt.Scale( scheme=&#39;redblue&#39;, domain=[-1, 0, 1] ) ), tooltip=[ alt.Tooltip(&#39;x_feature:O&#39;), alt.Tooltip(&#39;y_feature:O&#39;), alt.Tooltip(&#39;corr:Q&#39;, title=&#39;correlation&#39;) ] ) # text text = base.mark_text(baseline=&#39;middle&#39;).encode( text=alt.Text(&#39;corr:Q&#39;,format=&#39;.2f&#39;), color=alt.condition( np.abs(alt.datum.corr) &lt;= 0.5, alt.value(&#39;black&#39;), alt.value(&#39;white&#39;) ) ) return (heatmap + text).configure_view(step=size) . . Key Points . While the media tends to focus on anti-lockdown protests, which are largely comprised of White Republicans, those counties have only very recently (mid-August) experienced a higher number of COVID cases per capita. | The first COVID wave disproportionately affected counties with a high population density (notably New York City). However, counties with higher Black and Hispanic populations are now experiencing a higher number of COVID cases per capita--which may contribute to their higher degree of concern for the virus. | . It is a safe assumption that population density (pop_density) ought to be most positively correlated to COVID-19 cases per capita. However, below is a table showing the top correlations (weighted by county population) with new COVID-19 cases in the last 15 days. . #collapse-hide columns = column_selector(info_df, &#39;none&#39;, exclude=[&#39;male&#39;, &#39;female&#39;, &#39;tot&#39;, &#39;never&#39;, &#39;rarely&#39;, &#39;sometimes&#39;, &#39;frequently&#39;, &#39;always&#39;, &#39;bachelors&#39;, &#39;graduate&#39;]) make_correlation_table(nyt_df, info_df, x_cols=columns, y_cols=[&#39;new_cases_per_100k_15d&#39;], threshold=0.1) . . new_cases_per_100k_15d new_cases_15d . per_edu_hispanic_nohs 0.19295 | 0.19811 | . per_edu_white_nohs 0.192948 | -0.22322 | . per_edu_other_nohs 0.143057 | 0.112029 | . per_gop 0.135533 | -0.419843 | . per_pop_hispanic 0.13355 | 0.574996 | . per_edu_black_nohs 0.11599 | -0.133431 | . lon -0.103768 | -0.305254 | . age_pop_hispanic -0.120035 | 0.299972 | . per_pop_asian -0.126569 | 0.351137 | . edu_twoplus -0.139107 | 0.1884 | . per_pop_white -0.150093 | -0.569127 | . edu_black -0.150502 | 0.131369 | . edu_white -0.164875 | 0.332963 | . edu_hispanic -0.165315 | -0.158955 | . per_votes -0.176632 | -0.465718 | . pop_density -0.178967 | 0.176561 | . median_income_twoplus -0.185428 | 0.164721 | . age_pop -0.189542 | -0.191623 | . median_income_white -0.222087 | 0.236895 | . mask -0.257699 | 0.32943 | . lat -0.321788 | -0.272142 | . Generalizing the above table, we find the following factors to be most positively correlated: . percent of hispanic, white, other, and black population without a HS diploma | percent of two-party voters who voted GOP in the 2016 general election | percent population hispanic | . ...and the following the most negatively correlated: . educational attainment | percent population asian or white | percent of eligible voters who voted in the 2016 general election | population density | median age | mask discipline | latitude | . Contrary to our initial assumption, dense counties seem to be doing better than their less dense counterparts with regards to recent COVID-19 cases. . Counties which feature a larger proportion of uneducated white and hispanic residents seem to be suffering from a higher concentration of COVID cases--at least in the last 15 days. . Important: Correlations do not imply causation. . #collapse-hide columns = column_selector( info_df, [&#39;per_gop&#39;, &#39;mask&#39;, &#39;edu&#39;, &#39;median_income&#39;, &#39;age_pop&#39;, &#39;pop_density&#39;], mask=[&#39;per&#39;, &#39;pop&#39;], exclude=[&#39;male&#39;, &#39;female&#39;, &#39;tot&#39;] ) make_correlation_heatmap(nyt_df, info_df, x_cols=columns, y_cols=[&#39;cases_per_100k&#39;, &#39;new_cases_per_100k_15d&#39;], size=50) . . positive correlations y_feature x_feature corr 40 edu median_income 0.7337 66 edu per_pop_asian 0.4250 41 mask median_income 0.4294 67 mask per_pop_asian 0.4586 93 mask per_pop_hispanic 0.4599 147 per_gop per_pop_white 0.6777 44 per_pop_asian median_income 0.6062 135 per_pop_asian per_pop_twoplus 0.4405 176 per_pop_hispanic cases_per_100k 0.4958 215 per_pop_hispanic new_cases_15d 0.5750 139 per_pop_pacific per_pop_twoplus 0.8461 negative correlations y_feature x_feature corr 53 edu per_gop -0.4200 54 mask per_gop -0.6443 212 per_gop new_cases_15d -0.4198 160 per_gop pop_density -0.4707 57 per_pop_asian per_gop -0.5709 149 per_pop_black per_pop_white -0.4284 150 per_pop_hispanic per_pop_white -0.7645 206 per_pop_white cases -0.5476 180 per_pop_white cases_per_100k -0.5812 37 per_pop_white mask -0.5241 76 per_pop_white per_pop_asian -0.4923 . First, let&#39;s discuss features that not quite independent from each other: . selected positive correlations (&gt; 0.4): . educational attainment and median income | educational attainment and percent asian | mask discipline and median income | mask discipline and percent asian | mask discipline and percent hispanic | median income and percent asian | percent GOP and percent white | . selected negative correlations (&lt; -0.4): . educational attainment and percent GOP | mask discipline and percent GOP | mask discipline and percent white | percent Asian and percent GOP | population density and percent GOP | . Since there seems to be multicollinearity, we can&#39;t simply throw our data into a multiple linear regression. . Halving the Country: Measuring COVID-19 Cases along Demographic Features . #collapse-hide def df_splitter(info_df, split_on, splits=2, equal_pop=True, mode=&#39;verbose&#39;): if mode not in [&#39;verbose&#39;, &#39;mean&#39;, &#39;percentile&#39;]: mode = verbose info_df = info_df[~info_df[split_on].isna()].sort_values(by=split_on) if equal_pop: # https://stackoverflow.com/a/31871770/14083095 # splitting df into approx equal populations info_df[&#39;pop_cumsum&#39;] = info_df[&#39;tot_pop&#39;].cumsum() subpop = info_df[&#39;pop_cumsum&#39;].max() / splits info_df[&#39;split&#39;] = (info_df[&#39;pop_cumsum&#39;] / subpop).apply(math.ceil) else: # splitting df into approx equal shapes info_df[&#39;split&#39;] = pd.qcut(info_df[split_on], splits) replace_dict = {} to_replace = info_df[&#39;split&#39;].unique() # renaming our splits into something more readable for i, s in enumerate(to_replace): if mode == &#39;verbose&#39;: replace_dict[s] = f&quot;[{info_df.loc[info_df[&#39;split&#39;]==s,split_on].min():.2f},&quot; f&quot; {info_df.loc[info_df[&#39;split&#39;]==s,split_on].max():.2f}]&quot; elif mode == &#39;mean&#39;: replace_dict[s] = np.round( info_df.loc[info_df[&#39;split&#39;]==s,split_on].mean(), decimals=3 ) else: replace_dict[s] = (100/splits) * (int(i)+1) info_df[&#39;split&#39;] = info_df[&#39;split&#39;].replace(replace_dict) return info_df def make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=None, equal_pop=True ): y_title = split_on y_subtitle = &#39;county&#39; if equal_pop: y_subtitle = &#39;pop&#39; # check number of splits and only split on numeric columns # otherwise, use names as the different lines (setting splits=1) splits = int(splits) if split_on in info_df.select_dtypes(exclude=&#39;number&#39;).columns: splits = 1 y_ = [y] if &#39;_per_100k&#39; in y: y_ = [y.replace(&#39;_per_100k&#39;, &#39;&#39;)] elif y is &#39;mortality_rate&#39;: y_ = [&#39;cases&#39;, &#39;deaths&#39;] # first split df so that we can plot different lines if splits &gt; 1: info_df = df_splitter(info_df, split_on, splits, equal_pop) merged = df_merger( nyt_df, info_df, x_cols=[split_on, &#39;split&#39;], y_cols=y_, date=&#39;all&#39;, weight=&#39;tot_pop&#39; ) # &#39;split&#39; column generated by df_splitter() split_on = &#39;split&#39; else: merged = df_merger( nyt_df, info_df, x_cols=[split_on], y_cols=y_, date=&#39;all&#39; ) # recalculate aggregates if &#39;_per_100k&#39; in y: y_ = y.replace(&#39;_per_100k&#39;, &#39;&#39;) data = merged.groupby(by=[&#39;date&#39;, split_on])[y_].sum().fillna(0) / merged.groupby(by=[&#39;date&#39;, split_on])[&#39;tot_pop&#39;].sum() * 100_000 elif y is &#39;mortality_rate&#39;: data = merged.groupby(by=[&#39;date&#39;, split_on])[&#39;deaths&#39;].sum() / merged.groupby(by=[&#39;date&#39;, split_on])[&#39;cases&#39;].sum() # elif y is &#39;mortality_rate&#39;: # data = merged.groupby(by=[&#39;date&#39;, split_on])[y_].sum().fillna(0) # / merged.groupby(by=[&#39;date&#39;, split_on])[&#39;tot_pop&#39;].sum() else: data = merged.groupby(by=[&#39;date&#39;, split_on])[y].sum().fillna(0) data = data.reset_index().rename(columns={0: y}) # nearest point selection nearest = alt.selection(type=&#39;single&#39;, nearest=True, on=&#39;mouseover&#39;, fields=[&#39;date&#39;], empty=&#39;none&#39;) # base line chart lines = alt.Chart(data).mark_line().encode( x=&#39;date:T&#39;, y=alt.Y( f&#39;{y}:Q&#39;, title=y.replace(&#39;_&#39;, &#39; &#39;) ), color=f&#39;{split_on}:N&#39; ) # selects nearest points based on date selectors = alt.Chart(data).mark_point().encode( x=&#39;date:T&#39;, opacity=alt.value(0) ).add_selection(nearest) # marks a point on line where selected points = lines.mark_point().encode( opacity=alt.condition(nearest, alt.value(1), alt.value(0)) ) # white background for text white_text = lines.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=3).encode( text=alt.condition(nearest, f&#39;{y}:Q&#39;, alt.value(&#39; &#39;), format=&#39;.1f&#39;) ) # text showing y value text = lines.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=alt.condition(nearest, f&#39;{y}:Q&#39;, alt.value(&#39; &#39;), format=&#39;.1f&#39;) ) # rule showing nearest selector rules = alt.Chart(data).mark_rule(color=&#39;gray&#39;).encode( x=&#39;date:T&#39;, size=alt.value(1) ).transform_filter(nearest) return alt.layer( lines, selectors, points, rules, white_text, text ).configure_axis( gridDash=[1,2] ).properties( width=540, height=320, title=f&#39;{y} vs. {y_title}&#39; ) . . Dense counties (notably New York City) suffered high COVID cases early on. Up until about mid-July, however, lower-density counties have had a higher proportion of COVID cases. . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;pop_density&#39;, equal_pop=True) . . Republican-leaning counties have also only very recently had higher COVID cases than their Democrat-leaning counterparts. Note that there is a considerable amount of collinearity between population density and percent GOP (-0.47 correlation). . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;per_gop&#39;, equal_pop=True) . . Counties with a higher white population have been doing relatively well with COVID (up until now). . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;per_pop_white&#39;, equal_pop=True) . . Counties with higher Black and Hispanic populations have been disproportionately affected by COVID as well. Recall the COVID sentiment survey: White respondents are, on average, less concerned with COVID than Black and Hispanic respondents. Perhaps this has to do with them not being as negatively affected by the virus. . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;per_pop_black&#39;, equal_pop=True) . . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;per_pop_hispanic&#39;, equal_pop=True) . . Counties with lower educational attainment are now experiencing a disproportionate amount of COVID cases. . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;edu&#39;, equal_pop=True) . . Counties with higher mask discipline are experiencing a lower rate of COVID cases--however only since mid-July. . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;mask&#39;, equal_pop=True) . . Counties with higher median income also have a lower rate of COVID cases. . #collapse-hide make_line_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=2, split_on=&#39;median_income&#39;, equal_pop=True) . . Visualizing Via Heatmap . If we want to gain more resolution by having more splits, the line chart can get a little difficult to read. Therefore, we can visualize those relationships using both a heatmap and corresponding bar chart for clarity. . #collapse-hide def make_heatmap_timeseries( nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=10, split_on=None, equal_pop=True, mode=&#39;percentile&#39; ): y_title = split_on y_subtitle = &#39;county&#39; if equal_pop: y_subtitle = &#39;pop&#39; # check number of splits and only split on numeric columns # otherwise, use names as the different lines (setting splits=1) splits = int(splits) if split_on in info_df.select_dtypes(exclude=&#39;number&#39;).columns: splits = 1 y_ = [y] if &#39;_per_100k&#39; in y: y_ = [y.replace(&#39;_per_100k&#39;, &#39;&#39;)] elif y is &#39;mortality_rate&#39;: y_ = [&#39;cases&#39;, &#39;deaths&#39;] # first split df so that we can plot different lines if splits &gt; 1: info_df = df_splitter(info_df, split_on, splits, equal_pop, mode) merged = df_merger( nyt_df, info_df, x_cols=[split_on, &#39;split&#39;], y_cols=y_, date=&#39;all&#39;, weight=&#39;tot_pop&#39; ) # &#39;split&#39; column generated by df_splitter() split_on = &#39;split&#39; else: merged = df_merger( nyt_df, info_df, x_cols=[split_on], y_cols=y_, date=&#39;all&#39; ) # recalculate aggregates if &#39;_per_100k&#39; in y: y_ = y.replace(&#39;_per_100k&#39;, &#39;&#39;) data = merged.groupby(by=[&#39;date&#39;, split_on])[y_].sum().fillna(0) / merged.groupby(by=[&#39;date&#39;, split_on])[&#39;tot_pop&#39;].sum() * 100_000 elif y is &#39;mortality_rate&#39;: data = merged.groupby(by=[&#39;date&#39;, split_on])[&#39;deaths&#39;].sum() / merged.groupby(by=[&#39;date&#39;, split_on])[&#39;cases&#39;].sum() else: data = merged.groupby(by=[&#39;date&#39;, split_on])[y].sum().fillna(0) data = data.reset_index().rename(columns={0: y}) y_alt = f&#39;{split_on}:O&#39; # nearest point selection nearest = alt.selection(type=&#39;single&#39;, nearest=True, on=&#39;mouseover&#39;, fields=[&#39;date&#39;], empty=&#39;all&#39;) # title dx = 160 dy = splits*9 title = alt.Chart(data).mark_text(dx=dx, dy=dy, size=20).encode( text=&#39;monthdate(date):T&#39; ).transform_filter(nearest) w_title = alt.Chart(data).mark_text(dx=dx, dy=dy, stroke=&#39;white&#39;, strokeWidth=3, size=20).encode( text=&#39;monthdate(date):T&#39; ).transform_filter(nearest) # right panel: heatmap heatmap = alt.Chart(data).mark_rect().encode( alt.X( &#39;monthdate(date):T&#39;, axis=alt.Axis(format=&#39;%b %d&#39;) ), alt.Y( y_alt, sort=alt.EncodingSortField(f&#39;{split_on}&#39;, order=&#39;descending&#39;), title=f&#39;{y_title} ({y_subtitle} {mode})&#39; ), color=alt.Color( f&#39;{y}:Q&#39;, scale=alt.Scale( scheme=&#39;lightmulti&#39; ) ) ).add_selection(nearest) # left panel: bar chart bars = alt.Chart(data).mark_bar().encode( alt.X( f&#39;{y}:Q&#39;, scale=alt.Scale( domain=[0, data[y].max()] ) ), alt.Y( y_alt, sort=alt.EncodingSortField(f&#39;{split_on}&#39;, order=&#39;descending&#39;), title=f&#39;{y_title} ({y_subtitle} {mode})&#39; ), color=alt.Color( f&#39;{y}:Q&#39;, scale=alt.Scale( scheme=&#39;lightmulti&#39; ) ), tooltip=[ alt.Tooltip(f&#39;{y}:Q&#39;), alt.Tooltip(y_alt), ] ).transform_filter(nearest) # selects nearest points based on date selectors = alt.Chart(data).mark_point().encode( x=&#39;monthdate(date):T&#39;, opacity=alt.value(0) ).add_selection(nearest) return (heatmap | bars+w_title+title).properties( title=f&#39;{y} vs {y_title}&#39; ) . . We see how dense counties were almost exclusively hit first. However, the second wave seems to be affecting counties of all population densities. . #collapse-hide make_heatmap_timeseries(nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=10, split_on=&#39;pop_density&#39;, equal_pop=True, mode=&#39;percentile&#39;) . . We see with more clarity how Republican counties have actually done much better than Democratic ones only up until recently. Again, since population density is collinear with percent GOP, this chart is essentially an inverse of the population density chart above. . #collapse-hide make_heatmap_timeseries(nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=10, split_on=&#39;per_gop&#39;, equal_pop=True, mode=&#39;percentile&#39;) . . Mask discipline also has not shown much correlation until recently. Democratic-leaning urban centers tend to have higher mask discipline, which can explain the early cases among higher-percentile counties. However, we see that counties with lower mask discipline are experiencing a higher number of cases. . make_heatmap_timeseries(nyt_df, info_df, y=&#39;new_cases_per_100k_15sg&#39;, splits=10, split_on=&#39;mask&#39;, equal_pop=True, mode=&#39;percentile&#39;) . Conclusion . COVID-19 affected dense counties first | Later cases have since moved to less dense counties, which happen to be more Republican-leaning and have lower mask discipline. | Republican counties have only very recently (mid-August) experienced a higher number of COVID cases per capita. | .",
            "url": "https://jydiw.github.io/jydir/covid-19/data-visualization/2020/09/03/covid-misconceptions.html",
            "relUrl": "/covid-19/data-visualization/2020/09/03/covid-misconceptions.html",
            "date": " • Sep 3, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jydiw.github.io/jydir/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jydiw.github.io/jydir/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jydiw.github.io/jydir/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jydiw.github.io/jydir/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}